{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68244464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install httpcore\n",
    "#! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e088e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import json\n",
    "import tiktoken\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "import json\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "# Specify the source and destination folders\n",
    "parsed_resumes = 'parsed_successfully'\n",
    "failed_resumes = 'failed_to_parse'\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \""\n",
    "#openai.api_key = \""\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3245e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_questions = \"\"\"Summarize the text below into a JSON with the following structure {basic_info: {first_name, last_name, full_name, email, summary, skills, phone_number, location, portfolio_website_url, linkedin_url, github_main_page_url, university, education_level (BS, MS, or PhD), graduation_year, graduation_month, majors, GPA}, work_experience: [{job_title, company, location, duration}], project_experience:[{project_name, project_description}]}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d2db0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of documents are:  0\n"
     ]
    }
   ],
   "source": [
    "directory = './resumes/'\n",
    "\n",
    "def load_docs(directory):\n",
    "    loader = DirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "documents = load_docs(directory)\n",
    "print(\"The number of documents are: \", len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af91e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "\n",
    "def num_tokens_from_string(string: str, model: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de162160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_completion(input_string: str, prompt: str,\n",
    "                    engine: str = 'gpt-3.5-turbo-1106',\n",
    "                    temperature: float = 0.0,\n",
    "                    top_p: int = 1,\n",
    "                    frequency_penalty: int = 0,\n",
    "                    max_tokens: int = 4097,\n",
    "                    presence_penalty: int = 0) -> object:\n",
    "    \"\"\"\n",
    "    Base function for querying GPT-3. \n",
    "    Send a request to GPT-3 with the passed-in function parameters and return the response object.\n",
    "    :param prompt: GPT-3 completion prompt.\n",
    "    :param engine: The engine, or model, to generate completion.\n",
    "    :param temperature: Controls the randomnesss. Lower means more deterministic.\n",
    "    :param max_tokens: Maximum number of tokens to be used for prompt and completion combined.\n",
    "    :param top_p: Controls diversity via nucleus sampling.\n",
    "    :param frequency_penalty: How much to penalize new tokens based on their existence in text so far.\n",
    "    :param presence_penalty: How much to penalize new tokens based on whether they appear in text so far.\n",
    "    :return: GPT-3 response object\n",
    "    \"\"\"\n",
    "    #logger.info(f'query_completion: using {engine}')\n",
    "\n",
    "    estimated_prompt_tokens = num_tokens_from_string(prompt, engine)\n",
    "    estimated_input_tokens = num_tokens_from_string(input_string, engine)\n",
    "    estimated_answer_tokens = (max_tokens - estimated_prompt_tokens - estimated_input_tokens)\n",
    "    print(\"Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens: \", estimated_prompt_tokens, estimated_input_tokens, estimated_answer_tokens, max_tokens)\n",
    "    \n",
    "    if(estimated_input_tokens <= 2400):\n",
    "        response = client.chat.completions.create(\n",
    "        model=engine,\n",
    "        messages=[\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": input_string\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": prompt\n",
    "        }\n",
    "        ],  \n",
    "        temperature=temperature,\n",
    "        #max_tokens=estimated_answer_tokens,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty\n",
    "        )\n",
    "        return response\n",
    "    else:\n",
    "        print(\"The resume length is too huge, check the resume once\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70c10620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_resume(prompt_questions : str, pdf_str: str) -> dict:\n",
    "    \"\"\"\n",
    "    Query GPT-3 for the work experience and / or basic information from the resume at the PDF file path.\n",
    "    :param pdf_path: Path to the PDF file.\n",
    "    :return dictionary of resume with keys (basic_info, work_experience).\n",
    "    \"\"\"\n",
    "    resume = {}\n",
    "    #pdf_str = self.pdf2string(pdf_path)\n",
    "    #print(pdf_str)\n",
    "    \n",
    "    \n",
    "    #prompt = prompt_questions + ':\\n' + pdf_str\n",
    "\n",
    "    # Reference: https://platform.openai.com/docs/models/gpt-3-5\n",
    "    engine = 'gpt-3.5-turbo-1106'\n",
    "    max_tokens = 4097\n",
    "\n",
    "    response = query_completion(prompt=prompt_questions,input_string = pdf_str,engine=engine, max_tokens = max_tokens)\n",
    "    response_text = response.choices[0].message.content.strip()#response['choices'][0]['text'].strip()\n",
    "    # Add double quotes around keys using regular expressions\n",
    "    response_text = re.sub(r'(\\w+):', r'\"\\1\":', response_text)\n",
    "    # Find the first \"{\" and last \"}\" positions\n",
    "    #start_index = response_text.find(\"{\")\n",
    "    #end_index = response_text.rfind(\"}\")\n",
    "    #response_text = response_text[start_index:]\n",
    "\n",
    "    #print(response_text)\n",
    "    try:\n",
    "        resume = json.loads(response_text)\n",
    "    except:\n",
    "        resume = str(response_text)\n",
    "    #print(resume)\n",
    "    return resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a264ad1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 0 4000 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Amy Halter Resume[39].docx'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 2152 1848 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Blake Mitchell Resume.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 1244 2756 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Bradley W. Branham - Addison Group.docx'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 13831 -9831 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\CASE STUDY What Makes A Leader - Daniel Goleman.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 1496 2504 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Chris Lobdell Resume 11212022.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 5322 -1322 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\Clark, Dan_TimeDoc CEO (1).pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 2490 1510 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\Craig Jones_Resume.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 785 3215 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Dennis Ratzker.docx'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 1485 2515 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\DeWitt Bio Jan 2023.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 0 4000 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Equis Contract- CRG_2016.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 1444 2556 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Faisal Rusho.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 3166 834 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\Heidi Lorenzen Sep 2023 (1).pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 9021 -5021 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\HRS-1H Update & Convertible Note.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 787 3213 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Ian Steward_Resume.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 2353 1647 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\JavierSaade.CareerProfile.W23.2.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 1859 2141 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Jeffrey Lortz CV.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 3244 756 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\John Paul Apholt_Resume 2023 (003).pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 2676 1324 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\Keshavkumar Ramesh Mishra.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 2362 1638 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Kirk Ziehm Resume - Dec 2022.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 2595 1405 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\Lance Pine Resume.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 1687 2313 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Mathilde Coste.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 2616 1384 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\Michael_DeSimone_Resume.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 3176 824 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\NMH CV - Oct 2021.docx'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 561 3439 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Nukalapati Snehitha - Resume.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 1409 2591 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Osvaldo Valdes.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 3840 160 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\Patrick M Mulvehill.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 3388 612 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\Project Surfliner Agenda - 6-28-2023.docx'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 0 4000 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Resume - DilipSumra.docx'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 1393 2607 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Salins, Lena - HL.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 2023 1977 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Sefton Cohen_Resume.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 1526 2474 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\TDolce_Resume.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 2681 1319 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\TimeDoc People Strategy_Final_11_16.pdf'})\n",
      "-------------------------------\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 1755 2245 4097\n",
      "Parsing Successful:  ('metadata', {'source': 'resumes\\\\Tommy Guercio Resume.pdf'})\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "#all_resumes = {}\n",
    "for i in documents:\n",
    "    pdf_str = list(i)[1][1]\n",
    "    file_name = list(i)[2][1]['source']\n",
    "\n",
    "    # Split the file path using \"\\\\\" as the delimiter\n",
    "    parts = file_name.split(\"resumes\\\\\")\n",
    "    # Get the last part of the split string and split it using \".\" as the delimiter\n",
    "    file_name_parts = parts[-1].split(\".\")\n",
    "    # Get the desired file name without the extension\n",
    "    file_name_parts = file_name_parts[0]\n",
    "    \n",
    "    try:\n",
    "        op = query_resume(prompt_questions=prompt_questions, pdf_str=pdf_str)\n",
    "        if type(op) is str:\n",
    "            # Open the file in write mode ('w')\n",
    "            with open('./parsed_resumes_json/'+file_name_parts+'.txt', 'w') as file:\n",
    "                # Write the string to the file\n",
    "                file.write(op)\n",
    "        else:\n",
    "            op[\"file_name\"] = parts[-1]\n",
    "            with open('./parsed_resumes_json/'+file_name_parts+'.json', 'w') as json_file:\n",
    "                json.dump(op, json_file)\n",
    "\n",
    "        # Move the file from the source folder to the destination folder\n",
    "        shutil.move(os.path.join('resumes', parts[-1]), os.path.join(parsed_resumes, parts[-1]))\n",
    "\n",
    "        #all_resumes[op[\"basic_info\"][\"full_name\"]] = op\n",
    "        print(\"Parsing Successful: \", list(i)[2])\n",
    "        print(\"-------------------------------\")\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        print(\"Some error in: \", list(i)[2])\n",
    "        # Move the file from the source folder to the destination folder\n",
    "        shutil.move(os.path.join('resumes', parts[-1]), os.path.join(failed_resumes, parts[-1]))\n",
    "        print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34586720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edba93a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n",
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  1  new resumes detected\n",
      "The number of documents are:  1\n",
      "Prompt Tokens, Input Tokens, Answer Tokens, Overall Tokens:  97 3166 834 4097\n",
      "The resume length is too huge, check the resume once\n",
      "'NoneType' object has no attribute 'choices'\n",
      "Some error in:  ('metadata', {'source': 'resumes\\\\Heidi Lorenzen Sep 2023 (1).pdf'})\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "import parsing_given_resumes\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "directory = './resumes/'\n",
    "\n",
    "def load_docs(directory):\n",
    "    loader = DirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "documents = load_docs(directory)\n",
    "\n",
    "if(len(documents) <= 0):\n",
    "    print(\"No New Resumes detected\")\n",
    "else:\n",
    "    print(\"There are \", len(documents), \" new resumes detected\")\n",
    "    parsing_given_resumes.parse_new_resumes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90dc36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
